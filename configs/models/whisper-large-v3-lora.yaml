# Model
model_name: "openai/whisper-large-v3"

# LoRA
use_lora: true
lora_r: 64
lora_alpha: 64
lora_dropout: 0.0
lora_target_modules:
  - "q_proj"
  - "v_proj"

# Training
gradient_checkpointing: true # Greatly reduces memory usage

# Whisper
language: "English"
task: "transcribe"
